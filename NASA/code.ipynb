{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2cd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Kepler exoplanet dataset, skipping the first 53 rows of metadata (Commented lines)\n",
    "kepler_data = pd.read_csv('kepler_exoplanet_data.csv', skiprows=53)\n",
    "\n",
    "# Drop the unnecessary columns like KEPID, KOI Name, Kepler Name, koi_tce_delivname.\n",
    "kepler_data = kepler_data.drop(columns=['kepid', 'kepoi_name', 'kepler_name', 'koi_tce_delivname'])\n",
    "\n",
    "# Convert the 'koi_disposition' column to categorical type\n",
    "kepler_data['koi_disposition'] = kepler_data['koi_disposition'].astype('category')\n",
    "categories = kepler_data['koi_disposition'].cat.categories\n",
    "\n",
    "# Map the categories to numerical codes and replace the original column 0 -> 'CANDIDATE', 2 -> 'FALSE POSITIVE', 1 -> 'CONFIRMED'\n",
    "kepler_data['koi_disposition'] = kepler_data['koi_disposition'].cat.codes\n",
    "\n",
    "#convert 'koi_pdisposition' to Categorical type\n",
    "kepler_data['koi_pdisposition'] = kepler_data['koi_pdisposition'].astype('category')\n",
    "kepler_data['koi_pdisposition'] = kepler_data['koi_pdisposition'].cat.codes\n",
    "\n",
    "#Check any character columns and convert them to categorical type\n",
    "for column in kepler_data.select_dtypes(include=['object']).columns:\n",
    "    print(f\"Column '{column}' is of type 'object'\")\n",
    "    kepler_data[column] = kepler_data[column].astype('category')\n",
    "    kepler_data[column] = kepler_data[column].cat.codes\n",
    "\n",
    "# identify columns with missing values and fill them with the median of the respective columns\n",
    "missing_value_columns = kepler_data.columns[kepler_data.isnull().any()]\n",
    "for column in missing_value_columns:\n",
    "    median_value = kepler_data[column].median()\n",
    "    kepler_data[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# verify the missing values have been handled\n",
    "# print(kepler_data.isnull().sum())\n",
    "\n",
    "\n",
    "print(kepler_data.head())\n",
    "\n",
    "\n",
    "# # Fill missing values in 'koi_prad' with the median value of the column\n",
    "# kepler_data['koi_prad'].fillna(kepler_data['koi_prad'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify skewed columns in kepler_data\n",
    "# skew_values = kepler_data.skew(numeric_only=True)\n",
    "\n",
    "# # List columns with high skewness\n",
    "# skewed_columns = skew_values[abs(skew_values) > 1].index.tolist()\n",
    "# # print(\"Highly skewed columns:\", skewed_columns)\n",
    "\n",
    "# # log-transform skewed features\n",
    "# for column in skewed_columns:\n",
    "#     # Apply RobustScaler to reduce the impact of outliers\n",
    "#     kepler_data[column] = np.log1p(kepler_data[column])\n",
    "\n",
    "# print(kepler_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "512b3136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing -inf values: []\n"
     ]
    }
   ],
   "source": [
    "data_to_scale = kepler_data.drop(columns=['koi_disposition', 'koi_pdisposition'])\n",
    "\n",
    "# Identify columns containing -inf values\n",
    "inf_columns = []\n",
    "for column in data_to_scale.columns:\n",
    "    if np.isneginf(data_to_scale[column]).any():\n",
    "        inf_columns.append(column)\n",
    "print(\"Columns containing -inf values:\", inf_columns)\n",
    "\n",
    "# Display rows for each column that contain -inf values\n",
    "for column in inf_columns:\n",
    "    inf_rows = data_to_scale[np.isneginf(data_to_scale[column])]\n",
    "    print(f\"Rows with -inf in column '{column}':\")\n",
    "    print(inf_rows[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb529504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sahw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\sahw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sahw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sahw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sahw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\SAHW\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return fnb._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "c:\\Users\\SAHW\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "# Apply RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "scaled_data = scaler.fit_transform(data_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c196d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
      "0   0.669347            0.0            0.0            0.0            0.0   \n",
      "1   0.638191            0.0            0.0            0.0            0.0   \n",
      "2  -0.335678            0.0            0.0            0.0            0.0   \n",
      "3  -0.335678            0.0            1.0            0.0            0.0   \n",
      "4   0.669347            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
      "0   -0.006972        -0.031124         0.031124     0.878239   \n",
      "1    1.175982         0.887989        -0.887989     0.666684   \n",
      "2    0.267138        -0.084605         0.084605     1.018263   \n",
      "3   -0.211047        -0.145881         0.145881     0.872145   \n",
      "4   -0.190283        -0.131277         0.131277     0.906099   \n",
      "\n",
      "   koi_time0bk_err1  ...  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
      "0         -0.227417  ...       -0.061069        0.307692 -0.152960   \n",
      "1         -0.070418  ...       -0.061069        0.307692 -0.152960   \n",
      "2         -0.409697  ...       -0.264631       -0.461538 -0.276585   \n",
      "3         -0.463492  ...       -0.173028       -0.384615 -0.437926   \n",
      "4         -0.346320  ...        0.000000       -0.788462  0.096386   \n",
      "\n",
      "   koi_srad_err1  koi_srad_err2        ra       dec  koi_kepmag  \\\n",
      "0      -0.669725       0.308642 -0.045412  0.751864    0.439426   \n",
      "1      -0.669725       0.308642 -0.045412  0.751864    0.439426   \n",
      "2      -0.082569       0.203704  0.658994  0.750597    0.486716   \n",
      "3      -0.229358       0.271605 -0.934447  0.776043    0.572264   \n",
      "4       0.380734      -0.135802 -0.487087  0.766104    0.525505   \n",
      "\n",
      "   koi_disposition  koi_pdisposition  \n",
      "0                1                 0  \n",
      "1                1                 0  \n",
      "2                0                 0  \n",
      "3                2                 1  \n",
      "4                1                 0  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert scaled_data (numpy array) back to DataFrame with original column names\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "\n",
    "# add back the label columns for ML training:\n",
    "final_df = pd.concat([scaled_df, kepler_data[['koi_disposition', 'koi_pdisposition']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee517d",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
